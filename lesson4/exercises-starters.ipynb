{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto\n",
      "  Using cached boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: boto\n",
      "Successfully installed boto-2.49.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/site-packages (1.17.23)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Collecting botocore<1.27.0,>=1.26.10\n",
      "  Using cached botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.10->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.23\n",
      "    Uninstalling botocore-1.20.23:\n",
      "      Successfully uninstalled botocore-1.20.23\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.4\n",
      "    Uninstalling s3transfer-0.3.4:\n",
      "      Successfully uninstalled s3transfer-0.3.4\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.23\n",
      "    Uninstalling boto3-1.17.23:\n",
      "      Successfully uninstalled boto3-1.17.23\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.19.23 requires botocore==1.20.23, but you have botocore 1.26.10 which is incompatible.\n",
      "awscli 1.19.23 requires s3transfer<0.4.0,>=0.3.0, but you have s3transfer 0.5.2 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.23.10 botocore-1.26.10 s3transfer-0.5.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: awscli in /usr/local/lib/python3.6/site-packages (1.19.23)\n",
      "Collecting awscli\n",
      "  Using cached awscli-1.24.10-py3-none-any.whl (3.9 MB)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.6/site-packages (from awscli) (5.4.1)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.6/site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /usr/local/lib/python3.6/site-packages (from awscli) (0.4.3)\n",
      "Requirement already satisfied: botocore==1.26.10 in /usr/local/lib/python3.6/site-packages (from awscli) (1.26.10)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.6/site-packages (from awscli) (0.15.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/site-packages (from awscli) (0.5.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.6/site-packages (from botocore==1.26.10->awscli) (1.25.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from botocore==1.26.10->awscli) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from botocore==1.26.10->awscli) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.26.10->awscli) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
      "Installing collected packages: awscli\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.19.23\n",
      "    Uninstalling awscli-1.19.23:\n",
      "      Successfully uninstalled awscli-1.19.23\n",
      "Successfully installed awscli-1.24.10\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /usr/local/lib/python3.6/site-packages (2.29.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.128.0.tar.gz (660 kB)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /usr/local/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "  Using cached sagemaker-2.127.0.tar.gz (655 kB)\n",
      "  Using cached sagemaker-2.126.0.tar.gz (654 kB)\n",
      "  Using cached sagemaker-2.125.0.tar.gz (654 kB)\n",
      "  Using cached sagemaker-2.124.0.tar.gz (654 kB)\n",
      "  Using cached sagemaker-2.123.0.tar.gz (667 kB)\n",
      "  Using cached sagemaker-2.122.0.tar.gz (629 kB)\n",
      "  Using cached sagemaker-2.121.2.tar.gz (620 kB)\n",
      "  Using cached sagemaker-2.121.1.tar.gz (620 kB)\n",
      "  Using cached sagemaker-2.121.0.tar.gz (620 kB)\n",
      "  Using cached sagemaker-2.120.0.tar.gz (620 kB)\n",
      "  Using cached sagemaker-2.119.0.tar.gz (617 kB)\n",
      "  Using cached sagemaker-2.118.0.tar.gz (614 kB)\n",
      "  Using cached sagemaker-2.117.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.6/site-packages (from sagemaker) (1.18.5)\n",
      "Collecting pathos\n",
      "  Using cached pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /usr/local/lib/python3.6/site-packages (from sagemaker) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/site-packages (from sagemaker) (20.9)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /usr/local/lib/python3.6/site-packages (from sagemaker) (1.23.10)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /usr/local/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Collecting schema\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /usr/local/lib/python3.6/site-packages (from sagemaker) (3.15.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /usr/local/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.10 in /usr/local/lib/python3.6/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.26.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.5.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3<2.0,>=1.20.21->sagemaker) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3<2.0,>=1.20.21->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/site-packages (from protobuf<4.0,>=3.1->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Collecting multiprocess>=0.70.12\n",
      "  Using cached multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "Collecting ppft>=1.6.6.4\n",
      "  Using cached ppft-1.6.6.4-py3-none-any.whl (65 kB)\n",
      "Collecting dill>=0.3.4\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pox>=0.3.0\n",
      "  Using cached pox-0.3.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting contextlib2>=0.5.5\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Installing collected packages: dill, ppft, pox, multiprocess, contextlib2, schema, pathos, sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.29.0\n",
      "    Uninstalling sagemaker-2.29.0:\n",
      "      Successfully uninstalled sagemaker-2.29.0\n",
      "Successfully installed contextlib2-21.6.0 dill-0.3.4 multiprocess-0.70.12.2 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 sagemaker-2.117.0 schema-0.7.5\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto --upgrade\n",
    "!pip install boto3 --upgrade\n",
    "!pip install awscli --upgrade\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-560402809124\n"
     ]
    }
   ],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"id\"] = range(len(df))\n",
    "\n",
    "# TODO: Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name='wine-features', sagemaker_session=session)\n",
    "\n",
    "# TODO: Load Feature definitions\n",
    "\n",
    "feature_group.load_feature_definitions(data_frame=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ResourceInUse",
     "evalue": "An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine-features already exists. Choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceInUse\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c3a30f9aa6ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mevent_time_feature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EventTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrole_arn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0menable_online_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, s3_uri, record_identifier_name, event_time_feature_name, role_arn, online_store_kms_key_id, enable_online_store, offline_store_kms_key_id, disable_glue_table_creation, data_catalog_config, description, tags)\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcreate_feature_store_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_feature_group\u001b[0;34m(self, feature_group_name, record_identifier_name, event_time_feature_name, feature_definitions, role_arn, online_store_config, offline_store_config, description, tags)\u001b[0m\n\u001b[1;32m   4118\u001b[0m             \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4119\u001b[0m         )\n\u001b[0;32m-> 4120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m     def describe_feature_group(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceInUse\u001b[0m: An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine-features already exists. Choose a different name."
     ]
    }
   ],
   "source": [
    "# Create the feature store:\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/features\",\n",
    "    record_identifier_name=\"id\",\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '5aebc06d-da7e-4305-8564-b0e8f10570c6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5aebc06d-da7e-4305-8564-b0e8f10570c6',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '823',\n",
       "   'date': 'Wed, 11 Jan 2023 13:46:44 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Record': [{'FeatureName': 'alcohol', 'ValueAsString': '14.23'},\n",
       "  {'FeatureName': 'malic_acid', 'ValueAsString': '1.71'},\n",
       "  {'FeatureName': 'ash', 'ValueAsString': '2.43'},\n",
       "  {'FeatureName': 'alcalinity_of_ash', 'ValueAsString': '15.6'},\n",
       "  {'FeatureName': 'magnesium', 'ValueAsString': '127.0'},\n",
       "  {'FeatureName': 'total_phenols', 'ValueAsString': '2.8'},\n",
       "  {'FeatureName': 'flavanoids', 'ValueAsString': '3.06'},\n",
       "  {'FeatureName': 'nonflavanoid_phenols', 'ValueAsString': '0.28'},\n",
       "  {'FeatureName': 'proanthocyanins', 'ValueAsString': '2.29'},\n",
       "  {'FeatureName': 'color_intensity', 'ValueAsString': '5.64'},\n",
       "  {'FeatureName': 'hue', 'ValueAsString': '1.04'},\n",
       "  {'FeatureName': 'od280_od315_of_diluted_wines', 'ValueAsString': '3.92'},\n",
       "  {'FeatureName': 'proline', 'ValueAsString': '1065.0'},\n",
       "  {'FeatureName': 'EventTime', 'ValueAsString': '1673443096.100877'},\n",
       "  {'FeatureName': 'id', 'ValueAsString': '0'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = session.boto_session.client(\n",
    "  'sagemaker-featurestore-runtime',\n",
    "  region_name=region)\n",
    "\n",
    "runtime.get_record(\n",
    "    FeatureGroupName=\"wine-features\",\n",
    "    RecordIdentifierValueAsString=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to ingest row 120: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 0: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 60: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 1: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 121: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 61: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 2: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 122: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 62: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 3: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 123: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 63: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 4: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 124: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 5: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 64: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 125: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 6: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 65: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 126: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 7: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 66: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 8: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 127: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 67: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 9: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 128: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 68: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 129: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 10: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 69: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 130: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 11: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 70: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 131: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 12: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 71: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 132: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 13: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 72: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 14: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 133: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 73: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 15: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 74: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 134: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 16: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 75: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 135: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 17: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 76: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 136: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 18: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 77: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 137: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 19: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 20: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 78: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 138: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 79: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 21: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 139: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 80: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 22: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 140: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 23: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 141: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 81: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 24: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 142: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 82: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 25: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 143: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 83: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 144: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 26: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 145: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 84: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 27: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 85: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 146: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 28: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 86: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 29: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 147: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 30: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 87: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 31: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 148: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 88: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 32: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 89: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 33: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 90: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 34: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 91: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 35: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 36: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 37: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 92: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 38: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 93: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 39: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 94: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 95: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 40: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 41: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 96: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 42: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 97: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 43: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 98: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 44: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 99: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 45: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 46: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 100: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 101: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 149: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 47: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 102: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 150: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 48: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 151: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 103: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 49: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 104: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 152: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 50: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 105: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 153: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 51: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 106: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 154: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 52: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 107: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 155: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 53: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 108: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 156: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 54: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 109: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 157: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 55: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 110: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 158: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 111: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 56: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 159: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 57: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 160: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 112: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 58: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 113: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 161: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 59: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 114: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 0 to 60\n",
      "Failed to ingest row 115: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 162: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 116: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 163: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 164: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 117: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 165: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 166: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 118: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 167: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 119: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 60 to 120\n",
      "Failed to ingest row 168: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 169: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 170: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 171: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 172: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 173: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 174: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 175: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 176: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 177: An error occurred (ValidationError) when calling the PutRecord operation: Validation Error: Provided values for Feature(s) [TARGET] which do not exist in FeatureGroup [wine-features].\n",
      "Failed to ingest row 120 to 178\n"
     ]
    },
    {
     "ename": "IngestionError",
     "evalue": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177] -> Failed to ingest some data into FeatureGroup wine-features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIngestionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2b037d9fe048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mingest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mingest\u001b[0;34m(self, data_frame, max_workers, max_processes, wait, timeout, profile_name)\u001b[0m\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_frame, wait, timeout)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \"\"\"\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_multi_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36m_run_multi_process\u001b[0;34m(self, data_frame, wait, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise IngestionError(\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_failed_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;34mf\"Failed to ingest some data into FeatureGroup {self.feature_group_name}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIngestionError\u001b[0m: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177] -> Failed to ingest some data into FeatureGroup wine-features"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-11 13:48:33 Starting - Starting the training job...ProfilerReport-1673444912: InProgress\n",
      "...\n",
      "2023-01-11 13:49:30 Starting - Preparing the instances for training.........\n",
      "2023-01-11 13:50:54 Downloading - Downloading input data......\n",
      "2023-01-11 13:51:49 Training - Downloading the training image...\n",
      "2023-01-11 13:52:35 Uploading - Uploading generated training model.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2023-01-11:13:52:29:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2023-01-11:13:52:29:INFO] File size need to be processed in the node: 0.01mb. Available memory size in the node: 8622.09mb\u001b[0m\n",
      "\u001b[34m[2023-01-11:13:52:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[13:52:29] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[13:52:29] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2023-01-11:13:52:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[13:52:29] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[13:52:29] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.759657#011validation-rmse:0.685354\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.616137#011validation-rmse:0.821641\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.501087#011validation-rmse:0.858446\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.430041#011validation-rmse:0.925116\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.377443#011validation-rmse:0.979923\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.337549#011validation-rmse:1.0265\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.309158#011validation-rmse:1.06425\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.287472#011validation-rmse:1.09787\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.273879#011validation-rmse:1.12296\u001b[0m\n",
      "\u001b[34m[13:52:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.264732#011validation-rmse:1.1432\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\n",
      "2023-01-11 13:52:48 Completed - Training job completed\n",
      "Training seconds: 113\n",
      "Billable seconds: 113\n"
     ]
    }
   ],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise: creating a data capture config. Configure your model to sample `34%` of inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "capture_uri = 's3://{bucket}/data-capture'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=34,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6030303239822388,0.6030303239822388,0.7861111164093018,0.6030303239822388,0.6030303239822388'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a DefaultModelMonitor and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2023-01-11-01-44-28-890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2023-01-11-01-44-28-890\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-560402809124/data/train.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-560402809124/model-monitor/baselining/baseline-suggestion-job-2023-01-11-01-44-28-890/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................................\u001b[34m2023-01-11 01:51:10,964 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:11.505486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:11.505520: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:13.087699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:13.087730: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:13.087750: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-207-28.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:13.088054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,631 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:560402809124:processing-job/baseline-suggestion-job-2023-01-11-01-44-28-890', 'ProcessingJobName': 'baseline-suggestion-job-2023-01-11-01-44-28-890', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-560402809124/data/train.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-560402809124/model-monitor/baselining/baseline-suggestion-job-2023-01-11-01-44-28-890/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::560402809124:role/service-role/AmazonSageMaker-ExecutionRole-20221219T171322', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,631 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,631 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,631 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,631 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,686 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,687 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,687 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,695 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,695 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:14,695 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,153 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.207.28\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop\u001b[0m\n",
      "\u001b[34m-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_342\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,166 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,169 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-a96fcdcc-5d64-4921-a69c-2557ae5e2412\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,640 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,651 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,653 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,655 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,660 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,660 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,660 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,660 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,690 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,703 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,703 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,707 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,707 INFO blockmanagement.BlockManager: The block deletion will start around 2023 Jan 11 01:51:15\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,709 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,709 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,710 INFO util.GSet: 2.0% max memory 3.1 GB = 63.1 MB\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,710 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,782 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,786 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,786 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,786 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,787 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,812 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,812 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,813 INFO util.GSet: 1.0% max memory 3.1 GB = 31.6 MB\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,813 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,815 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,815 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,815 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,815 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,819 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,823 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,823 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,823 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,823 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,829 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,829 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,829 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,832 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,832 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,834 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,834 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,834 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 969.5 KB\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,834 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,855 INFO namenode.FSImage: Allocated new BlockPoolId: BP-348260494-10.0.207.28-1673401875849\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,866 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,874 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,953 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,964 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,968 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.207.28\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:15,976 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:18,035 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:18,035 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:20,108 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:20,108 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:22,217 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:22,218 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:24,304 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:24,305 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:26,540 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:26,541 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:36,546 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:37 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:37 INFO  Main:30 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:37 INFO  Main:33 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:37 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkContext:54 - Running Spark version 2.3.4\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40697.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-d4ae0e82-c41c-45bb-96d4-5362785bb948\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:38 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.207.28:40697/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1673401898501\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  RMProxy:133 - Connecting to ResourceManager at /10.0.207.28:8032\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15575 MB per container)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:39 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:40 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:42 INFO  Client:54 - Uploading resource file:/tmp/spark-38afc596-fc15-4c5d-b8c5-fa9981ec76a9/__spark_libs__2280341593779116527.zip -> hdfs://10.0.207.28/user/root/.sparkStaging/application_1673401881650_0001/__spark_libs__2280341593779116527.zip\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  Client:54 - Uploading resource file:/tmp/spark-38afc596-fc15-4c5d-b8c5-fa9981ec76a9/__spark_conf__4093864840698896648.zip -> hdfs://10.0.207.28/user/root/.sparkStaging/application_1673401881650_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  Client:54 - Submitting application application_1673401881650_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  YarnClientImpl:310 - Submitted application application_1673401881650_0001\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:44 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1673401881650_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:45 INFO  Client:54 - Application report for application_1673401881650_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:45 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Wed Jan 11 01:51:45 +0000 2023] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1673401904176\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1673401881650_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:46 INFO  Client:54 - Application report for application_1673401881650_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:47 INFO  Client:54 - Application report for application_1673401881650_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:48 INFO  Client:54 - Application report for application_1673401881650_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:49 INFO  Client:54 - Application report for application_1673401881650_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:49 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1673401881650_0001), /proxy/application_1673401881650_0001\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:49 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  Client:54 - Application report for application_1673401881650_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.207.28\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1673401904176\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1673401881650_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  YarnClientSchedulerBackend:54 - Application application_1673401881650_0001 has started running.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43899.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  NettyBlockTransferService:54 - Server created on 10.0.207.28:43899\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.207.28, 43899, None)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.207.28:43899 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.207.28, 43899, None)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.207.28, 43899, None)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.207.28, 43899, None)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:50 INFO  log:192 - Logging initialized @13754ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:52 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.207.28:49942) with ID 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:51:52 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:42343 with 5.8 GB RAM, BlockManagerId(1, algo-1, 42343, None)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:08 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:08 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:08 INFO  DatasetReader:169 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/train.csv)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:08 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.4/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:08 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.4/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:09 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  CodeGenerator:54 - Code generated in 195.543799 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  CodeGenerator:54 - Code generated in 22.320791 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.7 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.207.28:43899 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  SparkContext:54 - Created broadcast 0 from csv at DatasetReader.scala:96\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  SparkContext:54 - Starting job: csv at DatasetReader.scala:96\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  DAGScheduler:54 - Got job 0 (csv at DatasetReader.scala:96) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at DatasetReader.scala:96)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:10 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:96), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.207.28:43899 (size: 4.4 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:96) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:42343 (size: 4.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:42343 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1865 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  DAGScheduler:54 - ResultStage 0 (csv at DatasetReader.scala:96) finished in 1.944 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:12 INFO  DAGScheduler:54 - Job 0 finished: csv at DatasetReader.scala:96, took 1.999033 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  CodeGenerator:54 - Code generated in 9.335475 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.207.28:43899 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  SparkContext:54 - Created broadcast 2 from csv at DatasetReader.scala:96\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceStrategy:54 - Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 12 more fields>\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 429.7 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.207.28:43899 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  SparkContext:54 - Created broadcast 3 from cache at DataAnalyzer.scala:98\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on algo-1:42343 in memory (size: 4.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 10.0.207.28:43899 in memory (size: 4.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  CodeGenerator:54 - Code generated in 54.874612 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:101\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:101) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:101)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[16] at head at DataAnalyzer.scala:101), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 0\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 30\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 34\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 32\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 33\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 31\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 35\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 10.0.207.28:43899 in memory (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  ContextCleaner:54 - Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on 10.0.207.28:43899 in memory (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on algo-1:42343 in memory (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 22.6 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 10.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.207.28:43899 (size: 10.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[16] at head at DataAnalyzer.scala:101) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:42343 (size: 10.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:42343 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  BlockManagerInfo:54 - Added rdd_11_0 in memory on algo-1:42343 (size: 10.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 464 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:101) finished in 0.527 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:101, took 0.533796 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DataAnalyzer:109 - The number of columns in the dataframe is 14\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:13 INFO  DataAnalyzer:136 - Number of shards is: 3\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  CodeGenerator:54 - Code generated in 24.196577 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Registering RDD 21 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[21] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 71.1 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.207.28:43899 (size: 25.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[21] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  YarnScheduler:54 - Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:14 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:42343 (size: 25.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 948 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 0.982 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[24] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 83.3 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.4 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.207.28:43899 (size: 28.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[24] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:42343 (size: 28.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 285 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.305 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:15 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 1.314259 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  CodeGenerator:54 - Code generated in 22.231776 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Got job 3 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[33] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 31.2 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.1 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.207.28:43899 (size: 13.1 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[33] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  YarnScheduler:54 - Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:42343 (size: 13.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 143 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - ResultStage 4 (treeReduce at KLLRunner.scala:107) finished in 0.155 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Job 3 finished: treeReduce at KLLRunner.scala:107, took 0.159086 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  CodeGenerator:54 - Code generated in 69.812591 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  CodeGenerator:54 - Code generated in 147.574996 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  CodeGenerator:54 - Code generated in 73.263408 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Registering RDD 38 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Got job 4 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 5 (MapPartitionsRDD[38] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 69.7 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.2 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.207.28:43899 (size: 24.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[38] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  YarnScheduler:54 - Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:16 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:42343 (size: 24.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 187 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - ShuffleMapStage 5 (collect at AnalysisRunner.scala:313) finished in 0.212 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 6)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[41] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 54.1 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.207.28:43899 (size: 16.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[41] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:42343 (size: 16.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 129 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - ResultStage 6 (collect at AnalysisRunner.scala:313) finished in 0.146 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Job 4 finished: collect at AnalysisRunner.scala:313, took 0.368514 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Registering RDD 48 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Got job 5 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[48] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 25.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.0.207.28:43899 (size: 11.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[48] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  YarnScheduler:54 - Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:17 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on algo-1:42343 (size: 11.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 1255 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - ShuffleMapStage 7 (countByKey at ColumnProfiler.scala:566) finished in 1.271 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Submitting ResultStage 8 (ShuffledRDD[49] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1965.0 B, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.0.207.28:43899 (size: 1965.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[49] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  YarnScheduler:54 - Adding task set 8.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on algo-1:42343 (size: 1965.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  YarnScheduler:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - ResultStage 8 (countByKey at ColumnProfiler.scala:566) finished in 0.093 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Job 5 finished: countByKey at ColumnProfiler.scala:566, took 1.380060 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Registering RDD 54 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Got job 6 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 71.1 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.6 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 10.0.207.28:43899 (size: 25.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  SparkContext:54 - Created broadcast 12 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  YarnScheduler:54 - Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on algo-1:42343 (size: 25.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 281 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  YarnScheduler:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - ShuffleMapStage 9 (collect at AnalysisRunner.scala:313) finished in 0.298 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[57] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 83.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 28.5 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 10.0.207.28:43899 (size: 28.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[57] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  YarnScheduler:54 - Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 10, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on algo-1:42343 (size: 28.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 3 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 10) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  YarnScheduler:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - ResultStage 10 (collect at AnalysisRunner.scala:313) finished in 0.174 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Job 6 finished: collect at AnalysisRunner.scala:313, took 0.479716 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  CodeGenerator:54 - Code generated in 12.282318 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Got job 7 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[66] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 31.1 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on 10.0.207.28:43899 (size: 13.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[66] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  YarnScheduler:54 - Adding task set 11.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 11, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on algo-1:42343 (size: 13.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 11) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  YarnScheduler:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - ResultStage 11 (treeReduce at KLLRunner.scala:107) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Job 7 finished: treeReduce at KLLRunner.scala:107, took 0.073630 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 46\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 350\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 339\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 10.0.207.28:43899 in memory (size: 16.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on algo-1:42343 in memory (size: 16.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 124\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 320\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 171\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 283\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 357\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 359\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 332\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 144\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 121\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 174\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 305\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 275\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 345\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 270\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 153\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 286\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 309\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 73\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 340\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 69\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 10.0.207.28:43899 in memory (size: 25.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on algo-1:42343 in memory (size: 25.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 76\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 114\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 56\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 111\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 355\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 151\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 348\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 279\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 112\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 107\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 134\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 140\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 164\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 43\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 276\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 138\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 147\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 319\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 278\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on 10.0.207.28:43899 in memory (size: 13.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on algo-1:42343 in memory (size: 13.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 294\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 148\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 55\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 296\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 328\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 103\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 316\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 312\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 175\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 304\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 143\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 158\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 271\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 96\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 90\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 93\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 314\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 165\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 317\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 89\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned shuffle 0\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 44\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 54\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.0.207.28:43899 in memory (size: 11.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on algo-1:42343 in memory (size: 11.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 72\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 64\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 99\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 269\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 86\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 154\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 113\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 308\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 334\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 102\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 285\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 352\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 360\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 368\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 128\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 167\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 322\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 74\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.0.207.28:43899 in memory (size: 24.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on algo-1:42343 in memory (size: 24.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 282\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 299\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 344\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned shuffle 1\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 161\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 166\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 324\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 353\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 354\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 152\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 62\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 321\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 211\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 61\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 60\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 162\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 295\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 155\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 136\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 142\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 176\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 125\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 288\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 120\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 364\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 116\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 109\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 361\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on algo-1:42343 in memory (size: 10.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 10.0.207.28:43899 in memory (size: 10.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 139\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 347\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 135\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 129\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 281\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 297\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 169\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 291\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 131\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 302\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 87\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 172\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 367\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 77\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 92\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 47\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 100\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on algo-1:42343 in memory (size: 1965.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 10.0.207.28:43899 in memory (size: 1965.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 318\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 108\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 251\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 307\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 82\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 274\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 300\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 338\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 75\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 80\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 157\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 150\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 146\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 45\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 115\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 160\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 363\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 98\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 315\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 101\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 81\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 273\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 301\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 310\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 83\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 127\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 326\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 106\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 333\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 110\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 335\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 58\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 94\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 78\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 122\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 311\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 330\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 105\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 325\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 97\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 57\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 346\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 303\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 168\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 85\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 349\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on algo-1:42343 in memory (size: 25.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_12_piece0 on 10.0.207.28:43899 in memory (size: 25.6 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 145\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 277\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 351\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 123\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned shuffle 3\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 52\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 71\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 272\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on 10.0.207.28:43899 in memory (size: 28.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_13_piece0 on algo-1:42343 in memory (size: 28.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 289\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 336\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 65\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 358\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 292\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 119\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 141\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 298\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 133\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 156\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 50\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 306\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 66\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 59\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on algo-1:42343 in memory (size: 13.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 10.0.207.28:43899 in memory (size: 13.1 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 149\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 280\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 365\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 159\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 284\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 91\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 67\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 362\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 293\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 323\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 42\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 290\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on algo-1:42343 in memory (size: 28.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 10.0.207.28:43899 in memory (size: 28.4 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 331\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 51\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 163\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 49\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 84\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 63\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 137\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 48\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned shuffle 2\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 95\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 268\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 337\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 329\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 170\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 88\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 130\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 173\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 287\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 327\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 126\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 70\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 53\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 356\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 366\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 117\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 118\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 104\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 79\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 132\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  ContextCleaner:54 - Cleaned accumulator 68\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  CodeGenerator:54 - Code generated in 79.463683 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  CodeGenerator:54 - Code generated in 42.321368 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Registering RDD 71 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Got job 8 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 69.2 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.9 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on 10.0.207.28:43899 (size: 23.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Adding task set 12.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 12, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on algo-1:42343 (size: 23.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 12) in 170 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - ShuffleMapStage 12 (collect at AnalysisRunner.scala:313) finished in 0.180 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[74] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 53.9 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on 10.0.207.28:43899 (size: 16.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[74] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Adding task set 13.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 13, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on algo-1:42343 (size: 16.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 4 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 13) in 116 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - ResultStage 13 (collect at AnalysisRunner.scala:313) finished in 0.131 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Job 8 finished: collect at AnalysisRunner.scala:313, took 0.318451 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Registering RDD 81 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Got job 9 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[81] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 25.9 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on 10.0.207.28:43899 (size: 11.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[81] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Adding task set 14.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 14, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on algo-1:42343 (size: 11.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 14) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - ShuffleMapStage 14 (countByKey at ColumnProfiler.scala:566) finished in 0.102 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 15)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting ResultStage 15 (ShuffledRDD[82] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 3.3 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1966.0 B, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on 10.0.207.28:43899 (size: 1966.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 15 (ShuffledRDD[82] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Adding task set 15.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 15, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on algo-1:42343 (size: 1966.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 5 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 15) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - ResultStage 15 (countByKey at ColumnProfiler.scala:566) finished in 0.092 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Job 9 finished: countByKey at ColumnProfiler.scala:566, took 0.204521 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  CodeGenerator:54 - Code generated in 10.025406 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Registering RDD 87 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Got job 10 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[87] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 62.7 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 22.3 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on 10.0.207.28:43899 (size: 22.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[87] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  YarnScheduler:54 - Adding task set 16.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 16, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:20 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on algo-1:42343 (size: 22.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 16) in 206 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - ShuffleMapStage 16 (collect at AnalysisRunner.scala:313) finished in 0.221 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[90] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 72.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.7 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on 10.0.207.28:43899 (size: 25.7 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Created broadcast 20 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[90] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Adding task set 17.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 17, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on algo-1:42343 (size: 25.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 6 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 17) in 167 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - ResultStage 17 (collect at AnalysisRunner.scala:313) finished in 0.183 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Job 10 finished: collect at AnalysisRunner.scala:313, took 0.425381 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  CodeGenerator:54 - Code generated in 26.529929 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Got job 11 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Final stage: ResultStage 18 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting ResultStage 18 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 30.5 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 12.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on 10.0.207.28:43899 (size: 12.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Adding task set 18.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 18, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on algo-1:42343 (size: 12.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 18) in 61 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - ResultStage 18 (treeReduce at KLLRunner.scala:107) finished in 0.086 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Job 11 finished: treeReduce at KLLRunner.scala:107, took 0.091758 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  CodeGenerator:54 - Code generated in 22.908553 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  CodeGenerator:54 - Code generated in 36.163091 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  CodeGenerator:54 - Code generated in 62.027499 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Registering RDD 104 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Got job 12 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Final stage: ResultStage 20 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 60.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 21.6 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on 10.0.207.28:43899 (size: 21.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Adding task set 19.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 19, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on algo-1:42343 (size: 21.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 19) in 64 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - ShuffleMapStage 19 (collect at AnalysisRunner.scala:313) finished in 0.080 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - waiting: Set(ResultStage 20)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting ResultStage 20 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 44.4 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.9 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on 10.0.207.28:43899 (size: 13.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Adding task set 20.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 20, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on algo-1:42343 (size: 13.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 7 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 20) in 89 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  YarnScheduler:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - ResultStage 20 (collect at AnalysisRunner.scala:313) finished in 0.105 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:21 INFO  DAGScheduler:54 - Job 12 finished: collect at AnalysisRunner.scala:313, took 0.193458 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Registering RDD 114 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Got job 13 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Final stage: ResultStage 22 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 21 (MapPartitionsRDD[114] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 25.9 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on 10.0.207.28:43899 (size: 11.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Created broadcast 24 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[114] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Adding task set 21.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 21, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on algo-1:42343 (size: 11.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 21) in 57 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - ShuffleMapStage 21 (countByKey at ColumnProfiler.scala:566) finished in 0.072 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 22)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting ResultStage 22 (ShuffledRDD[115] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 3.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1968.0 B, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on 10.0.207.28:43899 (size: 1968.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Created broadcast 25 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 22 (ShuffledRDD[115] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Adding task set 22.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 22, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on algo-1:42343 (size: 1968.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 8 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 22) in 43 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - ResultStage 22 (countByKey at ColumnProfiler.scala:566) finished in 0.052 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Job 13 finished: countByKey at ColumnProfiler.scala:566, took 0.131799 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  ConstraintGenerator:45 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  ConstraintGenerator:50 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c4\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c5\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c6\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c7\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c8\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c9\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c10\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c11\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c12\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c13\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  StatsGenerator:64 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  CodeGenerator:54 - Code generated in 8.474062 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  CodeGenerator:54 - Code generated in 6.696622 ms\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Registering RDD 120 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Got job 14 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Final stage: ResultStage 24 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 23 (MapPartitionsRDD[120] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 26.6 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on 10.0.207.28:43899 (size: 11.7 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[120] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Adding task set 23.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 23, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on algo-1:42343 (size: 11.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 23) in 70 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - ShuffleMapStage 23 (count at StatsGenerator.scala:66) finished in 0.080 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 24)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting ResultStage 24 (MapPartitionsRDD[123] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 7.5 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on 10.0.207.28:43899 (size: 3.9 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Created broadcast 27 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[123] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Adding task set 24.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 24, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on algo-1:42343 (size: 3.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 9 to 10.0.207.28:49942\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 24) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnScheduler:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - ResultStage 24 (count at StatsGenerator.scala:66) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  DAGScheduler:54 - Job 14 finished: count at StatsGenerator.scala:66, took 0.138976 s\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  StatsGenerator:69 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 89\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.5393258426966292,\n",
      "      \"sum\" : 137.0,\n",
      "      \"std_dev\" : 0.49845107893974944,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 2.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.1,\n",
      "            \"count\" : 41.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.1,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.3,\n",
      "            \"upper_bound\" : 1.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.4,\n",
      "            \"upper_bound\" : 1.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.5,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 1.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 1.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.9,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 48.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 12.6770786516854,\n",
      "      \"sum\" : 1128.2600000000007,\n",
      "      \"std_dev\" : 0.7047275387880579,\n",
      "      \"min\" : 11.03,\n",
      "      \"max\" : 14.34,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 11.03,\n",
      "            \"upper_bound\" : 11.360999999999999,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.360999999999999,\n",
      "            \"upper_bound\" : 11.692,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.692,\n",
      "            \"upper_bound\" : 12.023,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.023,\n",
      "            \"upper_bound\" : 12.354,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.354,\n",
      "            \"upper_bound\" : 12.685,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.685,\n",
      "            \"upper_bound\" : 13.016,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.016,\n",
      "            \"upper_bound\" : 13.347,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.347,\n",
      "            \"upper_bound\" : 13.678,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.678,\n",
      "            \"upper_bound\" : 14.009,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 14.009,\n",
      "            \"upper_bound\" : 14.34,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 12.08, 12.08, 12.0, 12.69, 12.29, 11.62, 12.47, 11.81, 12.29, 12.37, 12.29, 12.08, 12.6, 12.34, 11.82, 12.51, 12.42, 12.25, 12.72, 12.22, 11.61, 11.46, 12.52, 11.76, 11.41, 12.08, 11.03, 11.82, 12.42, 12.77, 12.0, 11.45, 11.56, 12.42, 13.05, 11.87, 12.07, 12.43, 11.79, 12.37, 12.04, 12.86, 12.88, 12.81, 12.7, 12.51, 12.6, 12.25, 12.53, 13.49, 12.84, 12.93, 13.36, 13.52, 13.62, 12.25, 13.16, 13.88, 12.87, 13.32, 13.08, 13.5, 12.79, 13.11, 13.23, 12.58, 13.17, 13.84, 12.45, 14.34, 13.48, 12.36, 13.69, 12.85, 12.96, 13.78, 13.73, 13.45, 12.82, 13.58, 13.4, 12.2, 12.77, 14.16, 13.71, 13.4, 13.27, 13.17, 14.13 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.825730337078651,\n",
      "      \"sum\" : 251.48999999999992,\n",
      "      \"std_dev\" : 1.2033482199753587,\n",
      "      \"min\" : 0.74,\n",
      "      \"max\" : 5.8,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.74,\n",
      "            \"upper_bound\" : 1.246,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.246,\n",
      "            \"upper_bound\" : 1.752,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.752,\n",
      "            \"upper_bound\" : 2.258,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.258,\n",
      "            \"upper_bound\" : 2.7640000000000002,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.7640000000000002,\n",
      "            \"upper_bound\" : 3.2699999999999996,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.2699999999999996,\n",
      "            \"upper_bound\" : 3.776,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.776,\n",
      "            \"upper_bound\" : 4.281999999999999,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.281999999999999,\n",
      "            \"upper_bound\" : 4.788,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.788,\n",
      "            \"upper_bound\" : 5.2940000000000005,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.2940000000000005,\n",
      "            \"upper_bound\" : 5.8,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.33, 1.83, 1.51, 1.53, 2.83, 1.99, 1.52, 2.12, 1.41, 1.07, 3.17, 2.08, 1.34, 2.45, 1.72, 1.73, 2.55, 1.73, 1.75, 1.29, 1.35, 3.74, 2.43, 2.68, 0.74, 1.39, 1.51, 1.47, 1.61, 3.43, 3.43, 2.4, 2.05, 4.43, 5.8, 4.31, 2.16, 1.53, 2.13, 1.63, 4.3, 1.35, 2.99, 2.31, 3.55, 1.24, 2.46, 4.72, 5.51, 3.59, 2.96, 2.81, 2.56, 3.17, 4.95, 3.88, 3.57, 5.04, 4.61, 3.24, 3.9, 3.12, 2.67, 1.9, 3.3, 1.29, 5.19, 4.12, 3.03, 1.68, 1.67, 3.83, 3.26, 3.27, 3.45, 2.76, 4.36, 3.7, 3.37, 2.58, 4.6, 3.03, 2.39, 2.51, 5.65, 3.91, 4.28, 2.59, 4.1 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.3632584269662913,\n",
      "      \"sum\" : 210.32999999999993,\n",
      "      \"std_dev\" : 0.26075420119381026,\n",
      "      \"min\" : 1.7,\n",
      "      \"max\" : 3.23,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.7,\n",
      "            \"upper_bound\" : 1.853,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.853,\n",
      "            \"upper_bound\" : 2.006,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.006,\n",
      "            \"upper_bound\" : 2.159,\n",
      "            \"count\" : 5.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.159,\n",
      "            \"upper_bound\" : 2.312,\n",
      "            \"count\" : 25.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.312,\n",
      "            \"upper_bound\" : 2.465,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.465,\n",
      "            \"upper_bound\" : 2.618,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.618,\n",
      "            \"upper_bound\" : 2.771,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.771,\n",
      "            \"upper_bound\" : 2.924,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.924,\n",
      "            \"upper_bound\" : 3.077,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.077,\n",
      "            \"upper_bound\" : 3.23,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.3, 2.32, 2.42, 2.26, 2.22, 2.28, 2.2, 2.74, 1.98, 2.1, 2.21, 1.7, 1.9, 2.46, 1.88, 1.98, 2.27, 2.12, 2.28, 1.94, 2.7, 1.82, 2.17, 2.92, 2.5, 2.5, 2.2, 1.99, 2.19, 1.98, 2.0, 2.42, 3.23, 2.73, 2.13, 2.39, 2.17, 2.29, 2.78, 2.3, 2.38, 2.32, 2.4, 2.4, 2.36, 2.25, 2.2, 2.54, 2.64, 2.19, 2.61, 2.7, 2.35, 2.72, 2.35, 2.2, 2.15, 2.23, 2.48, 2.38, 2.36, 2.62, 2.48, 2.75, 2.28, 2.1, 2.32, 2.38, 2.64, 2.7, 2.64, 2.38, 2.54, 2.58, 2.35, 2.3, 2.26, 2.6, 2.3, 2.69, 2.86, 2.32, 2.28, 2.48, 2.45, 2.48, 2.26, 2.37, 2.74 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c4\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 21.124719101123596,\n",
      "      \"sum\" : 1880.1,\n",
      "      \"std_dev\" : 2.4881869622876147,\n",
      "      \"min\" : 16.0,\n",
      "      \"max\" : 28.5,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 16.0,\n",
      "            \"upper_bound\" : 17.25,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 17.25,\n",
      "            \"upper_bound\" : 18.5,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18.5,\n",
      "            \"upper_bound\" : 19.75,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 19.75,\n",
      "            \"upper_bound\" : 21.0,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 21.0,\n",
      "            \"upper_bound\" : 22.25,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 22.25,\n",
      "            \"upper_bound\" : 23.5,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 23.5,\n",
      "            \"upper_bound\" : 24.75,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 24.75,\n",
      "            \"upper_bound\" : 26.0,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 26.0,\n",
      "            \"upper_bound\" : 27.25,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 27.25,\n",
      "            \"upper_bound\" : 28.5,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 23.6, 18.5, 22.0, 20.7, 18.0, 18.0, 19.0, 21.5, 16.0, 18.5, 18.0, 17.5, 18.5, 21.0, 19.5, 20.5, 22.0, 19.0, 22.5, 19.0, 20.0, 19.5, 21.0, 20.0, 21.0, 22.5, 21.5, 20.8, 22.5, 16.0, 19.0, 20.0, 28.5, 26.5, 21.5, 21.0, 21.0, 21.5, 28.5, 24.5, 22.0, 18.0, 20.0, 24.0, 21.5, 17.5, 18.5, 21.0, 25.0, 19.5, 24.0, 21.0, 20.0, 23.5, 20.0, 18.5, 21.0, 20.0, 21.5, 21.5, 21.5, 24.0, 22.0, 25.5, 18.5, 20.0, 22.0, 19.5, 27.0, 25.0, 22.5, 21.0, 20.0, 22.0, 18.5, 22.0, 22.5, 23.0, 19.5, 24.5, 25.0, 19.0, 19.5, 20.0, 20.5, 23.0, 20.0, 20.0, 24.5 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c5\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 96.10112359550561,\n",
      "      \"sum\" : 8553.0,\n",
      "      \"std_dev\" : 13.731817349728228,\n",
      "      \"min\" : 70.0,\n",
      "      \"max\" : 162.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 70.0,\n",
      "            \"upper_bound\" : 79.2,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 79.2,\n",
      "            \"upper_bound\" : 88.4,\n",
      "            \"count\" : 33.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 88.4,\n",
      "            \"upper_bound\" : 97.6,\n",
      "            \"count\" : 23.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 97.6,\n",
      "            \"upper_bound\" : 106.8,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 106.8,\n",
      "            \"upper_bound\" : 116.0,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 116.0,\n",
      "            \"upper_bound\" : 125.2,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 125.2,\n",
      "            \"upper_bound\" : 134.4,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 134.4,\n",
      "            \"upper_bound\" : 143.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 143.6,\n",
      "            \"upper_bound\" : 152.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 152.8,\n",
      "            \"upper_bound\" : 162.0,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 70.0, 81.0, 86.0, 80.0, 88.0, 98.0, 162.0, 134.0, 85.0, 88.0, 88.0, 97.0, 88.0, 98.0, 86.0, 85.0, 90.0, 80.0, 84.0, 92.0, 94.0, 107.0, 88.0, 103.0, 88.0, 84.0, 85.0, 86.0, 108.0, 80.0, 87.0, 96.0, 119.0, 102.0, 86.0, 82.0, 85.0, 86.0, 92.0, 88.0, 80.0, 122.0, 104.0, 98.0, 106.0, 85.0, 94.0, 89.0, 96.0, 88.0, 101.0, 96.0, 89.0, 97.0, 92.0, 112.0, 102.0, 80.0, 86.0, 92.0, 113.0, 123.0, 112.0, 116.0, 98.0, 103.0, 93.0, 89.0, 97.0, 98.0, 89.0, 88.0, 107.0, 106.0, 106.0, 90.0, 88.0, 111.0, 88.0, 105.0, 112.0, 96.0, 86.0, 91.0, 95.0, 102.0, 120.0, 120.0, 96.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c6\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.9616853932584277,\n",
      "      \"sum\" : 174.59000000000006,\n",
      "      \"std_dev\" : 0.5397923778036865,\n",
      "      \"min\" : 0.98,\n",
      "      \"max\" : 3.52,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.98,\n",
      "            \"upper_bound\" : 1.234,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.234,\n",
      "            \"upper_bound\" : 1.488,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.488,\n",
      "            \"upper_bound\" : 1.742,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.742,\n",
      "            \"upper_bound\" : 1.996,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.996,\n",
      "            \"upper_bound\" : 2.25,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.25,\n",
      "            \"upper_bound\" : 2.504,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.504,\n",
      "            \"upper_bound\" : 2.758,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.758,\n",
      "            \"upper_bound\" : 3.012,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.012,\n",
      "            \"upper_bound\" : 3.266,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.266,\n",
      "            \"upper_bound\" : 3.52,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.2, 1.6, 1.45, 1.38, 2.45, 3.02, 2.5, 1.6, 2.55, 3.52, 2.85, 2.23, 1.45, 2.56, 2.5, 2.2, 1.68, 1.65, 1.38, 2.36, 2.74, 3.18, 2.55, 1.75, 2.48, 2.56, 2.46, 1.98, 2.0, 1.63, 2.0, 2.9, 3.18, 2.2, 2.62, 2.86, 2.6, 2.74, 2.13, 2.22, 2.1, 1.51, 1.3, 1.15, 1.7, 2.0, 1.62, 1.38, 1.79, 1.62, 2.32, 1.54, 1.4, 1.55, 2.0, 1.38, 1.5, 0.98, 1.7, 1.93, 1.41, 1.4, 1.48, 2.2, 1.8, 1.48, 1.74, 1.8, 1.9, 2.8, 2.6, 2.3, 1.83, 1.65, 1.39, 1.35, 1.28, 1.7, 1.48, 1.55, 1.98, 1.25, 1.39, 1.68, 1.68, 1.8, 1.59, 1.65, 2.05 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c7\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.4377528089887643,\n",
      "      \"sum\" : 127.96000000000002,\n",
      "      \"std_dev\" : 0.8903663591484944,\n",
      "      \"min\" : 0.34,\n",
      "      \"max\" : 5.08,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.34,\n",
      "            \"upper_bound\" : 0.8140000000000001,\n",
      "            \"count\" : 32.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8140000000000001,\n",
      "            \"upper_bound\" : 1.288,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.288,\n",
      "            \"upper_bound\" : 1.7620000000000002,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7620000000000002,\n",
      "            \"upper_bound\" : 2.236,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.236,\n",
      "            \"upper_bound\" : 2.71,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.71,\n",
      "            \"upper_bound\" : 3.184,\n",
      "            \"count\" : 5.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.184,\n",
      "            \"upper_bound\" : 3.658,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.658,\n",
      "            \"upper_bound\" : 4.132000000000001,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.132000000000001,\n",
      "            \"upper_bound\" : 4.606,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.606,\n",
      "            \"upper_bound\" : 5.08,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.59, 1.5, 1.25, 1.46, 2.25, 2.26, 2.27, 0.99, 2.5, 3.75, 2.99, 2.17, 1.36, 2.11, 1.64, 1.92, 1.84, 2.03, 1.76, 2.04, 2.92, 2.58, 2.27, 2.03, 2.01, 2.29, 2.17, 1.6, 2.09, 1.25, 1.64, 2.79, 5.08, 2.13, 2.65, 3.03, 2.65, 3.15, 2.24, 2.45, 1.75, 1.25, 1.22, 1.09, 1.2, 0.58, 0.66, 0.47, 0.6, 0.48, 0.6, 0.5, 0.5, 0.52, 0.8, 0.78, 0.55, 0.34, 0.65, 0.76, 1.39, 1.57, 1.36, 1.28, 0.83, 0.58, 0.63, 0.83, 0.58, 1.31, 1.1, 0.92, 0.56, 0.6, 0.7, 0.68, 0.47, 0.92, 0.66, 0.84, 0.96, 0.49, 0.51, 0.7, 0.61, 0.75, 0.69, 0.68, 0.76 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c8\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.4149438202247191,\n",
      "      \"sum\" : 36.93,\n",
      "      \"std_dev\" : 0.12531419923227424,\n",
      "      \"min\" : 0.14,\n",
      "      \"max\" : 0.66,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.14,\n",
      "            \"upper_bound\" : 0.192,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.192,\n",
      "            \"upper_bound\" : 0.24400000000000002,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.24400000000000002,\n",
      "            \"upper_bound\" : 0.29600000000000004,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.29600000000000004,\n",
      "            \"upper_bound\" : 0.34800000000000003,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.34800000000000003,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.452,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.452,\n",
      "            \"upper_bound\" : 0.504,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.504,\n",
      "            \"upper_bound\" : 0.556,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.556,\n",
      "            \"upper_bound\" : 0.608,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.608,\n",
      "            \"upper_bound\" : 0.66,\n",
      "            \"count\" : 6.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.42, 0.52, 0.5, 0.58, 0.25, 0.17, 0.32, 0.14, 0.29, 0.24, 0.45, 0.26, 0.29, 0.34, 0.37, 0.32, 0.66, 0.37, 0.48, 0.39, 0.29, 0.24, 0.26, 0.6, 0.42, 0.43, 0.52, 0.3, 0.34, 0.43, 0.37, 0.32, 0.47, 0.43, 0.3, 0.21, 0.37, 0.39, 0.58, 0.4, 0.42, 0.21, 0.24, 0.27, 0.17, 0.6, 0.63, 0.53, 0.63, 0.58, 0.53, 0.53, 0.37, 0.5, 0.47, 0.29, 0.43, 0.4, 0.47, 0.45, 0.34, 0.22, 0.24, 0.26, 0.61, 0.53, 0.61, 0.48, 0.63, 0.53, 0.52, 0.5, 0.5, 0.6, 0.4, 0.41, 0.52, 0.43, 0.4, 0.39, 0.27, 0.4, 0.48, 0.44, 0.52, 0.43, 0.43, 0.53, 0.56 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c9\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.429213483146067,\n",
      "      \"sum\" : 127.19999999999996,\n",
      "      \"std_dev\" : 0.5674706837334035,\n",
      "      \"min\" : 0.55,\n",
      "      \"max\" : 3.58,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.55,\n",
      "            \"upper_bound\" : 0.8530000000000001,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8530000000000001,\n",
      "            \"upper_bound\" : 1.1560000000000001,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.1560000000000001,\n",
      "            \"upper_bound\" : 1.459,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.459,\n",
      "            \"upper_bound\" : 1.7620000000000002,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7620000000000002,\n",
      "            \"upper_bound\" : 2.0650000000000004,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.0650000000000004,\n",
      "            \"upper_bound\" : 2.3680000000000003,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.3680000000000003,\n",
      "            \"upper_bound\" : 2.6710000000000003,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.6710000000000003,\n",
      "            \"upper_bound\" : 2.974,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.974,\n",
      "            \"upper_bound\" : 3.277,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.277,\n",
      "            \"upper_bound\" : 3.58,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.38, 1.64, 1.63, 1.62, 1.99, 1.35, 3.28, 1.56, 1.77, 1.95, 2.81, 1.4, 1.35, 1.31, 1.42, 1.48, 1.42, 1.63, 1.63, 2.08, 2.49, 3.58, 1.22, 1.05, 1.44, 1.04, 2.01, 1.53, 1.61, 0.83, 1.87, 1.83, 1.87, 1.71, 2.01, 2.91, 1.35, 1.77, 1.76, 1.9, 1.35, 0.94, 0.83, 0.83, 0.84, 1.25, 0.94, 0.8, 1.1, 0.88, 0.81, 0.75, 0.64, 0.55, 1.02, 1.14, 1.3, 0.68, 0.86, 1.25, 1.14, 1.25, 1.26, 1.56, 1.87, 1.4, 1.55, 1.56, 1.14, 2.7, 2.29, 1.04, 0.8, 0.96, 0.94, 1.03, 1.15, 1.46, 0.97, 1.54, 1.11, 0.73, 0.64, 1.24, 1.06, 1.41, 1.35, 1.46, 1.35 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c10\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 5.289101112359549,\n",
      "      \"sum\" : 470.72999899999985,\n",
      "      \"std_dev\" : 2.884347761583861,\n",
      "      \"min\" : 1.28,\n",
      "      \"max\" : 13.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.28,\n",
      "            \"upper_bound\" : 2.452,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.452,\n",
      "            \"upper_bound\" : 3.6240000000000006,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6240000000000006,\n",
      "            \"upper_bound\" : 4.796,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.796,\n",
      "            \"upper_bound\" : 5.968000000000001,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.968000000000001,\n",
      "            \"upper_bound\" : 7.140000000000001,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.140000000000001,\n",
      "            \"upper_bound\" : 8.312000000000001,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.312000000000001,\n",
      "            \"upper_bound\" : 9.484,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 9.484,\n",
      "            \"upper_bound\" : 10.656,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 10.656,\n",
      "            \"upper_bound\" : 11.828,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.828,\n",
      "            \"upper_bound\" : 13.0,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.74, 2.4, 3.6, 3.05, 2.15, 3.25, 2.6, 2.5, 2.9, 4.5, 2.3, 3.3, 2.45, 2.8, 2.06, 2.94, 2.7, 3.4, 3.3, 2.7, 2.65, 2.9, 2.0, 3.8, 3.08, 2.9, 1.9, 1.95, 2.06, 3.4, 1.28, 3.25, 6.0, 2.08, 2.6, 2.8, 2.76, 3.94, 3.0, 2.12, 2.6, 4.1, 5.4, 5.7, 5.0, 5.45, 7.1, 3.85, 5.0, 5.7, 4.92, 4.6, 5.6, 4.35, 4.4, 8.21, 4.0, 4.9, 7.65, 8.42, 9.4, 8.6, 10.8, 7.1, 10.52, 7.6, 7.9, 9.01, 7.5, 13.0, 11.75, 7.65, 5.88, 5.58, 5.28, 9.58, 6.62, 10.68, 10.26, 8.66, 8.5, 5.5, 9.899999, 9.7, 7.7, 7.3, 10.2, 9.3, 9.2 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c11\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.8233707865168536,\n",
      "      \"sum\" : 73.27999999999997,\n",
      "      \"std_dev\" : 0.21912975900457662,\n",
      "      \"min\" : 0.48,\n",
      "      \"max\" : 1.71,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.48,\n",
      "            \"upper_bound\" : 0.603,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.603,\n",
      "            \"upper_bound\" : 0.726,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.726,\n",
      "            \"upper_bound\" : 0.849,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.849,\n",
      "            \"upper_bound\" : 0.972,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.972,\n",
      "            \"upper_bound\" : 1.095,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.095,\n",
      "            \"upper_bound\" : 1.218,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.218,\n",
      "            \"upper_bound\" : 1.341,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.341,\n",
      "            \"upper_bound\" : 1.464,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.464,\n",
      "            \"upper_bound\" : 1.587,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.587,\n",
      "            \"upper_bound\" : 1.71,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.07, 1.08, 1.05, 0.96, 1.15, 1.16, 1.16, 0.95, 1.23, 1.04, 1.42, 1.27, 1.04, 0.8, 0.94, 1.04, 0.86, 1.0, 0.88, 0.86, 0.96, 0.75, 0.9, 1.23, 1.1, 0.93, 1.71, 0.95, 1.06, 0.7, 0.93, 0.8, 0.93, 0.92, 0.73, 0.75, 0.86, 0.69, 0.97, 0.89, 0.79, 0.76, 0.74, 0.66, 0.78, 0.75, 0.73, 0.75, 0.82, 0.81, 0.89, 0.77, 0.7, 0.89, 0.91, 0.65, 0.6, 0.58, 0.54, 0.55, 0.57, 0.59, 0.48, 0.61, 0.56, 0.58, 0.6, 0.57, 0.67, 0.57, 0.57, 0.56, 0.96, 0.87, 0.68, 0.7, 0.78, 0.85, 0.72, 0.74, 0.67, 0.66, 0.57, 0.62, 0.64, 0.7, 0.59, 0.6, 0.61 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c12\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.242134831460676,\n",
      "      \"sum\" : 199.55000000000015,\n",
      "      \"std_dev\" : 0.6941367153330001,\n",
      "      \"min\" : 1.27,\n",
      "      \"max\" : 3.69,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.27,\n",
      "            \"upper_bound\" : 1.512,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.512,\n",
      "            \"upper_bound\" : 1.754,\n",
      "            \"count\" : 20.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.754,\n",
      "            \"upper_bound\" : 1.996,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.996,\n",
      "            \"upper_bound\" : 2.238,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.238,\n",
      "            \"upper_bound\" : 2.48,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.48,\n",
      "            \"upper_bound\" : 2.722,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.722,\n",
      "            \"upper_bound\" : 2.9639999999999995,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.9639999999999995,\n",
      "            \"upper_bound\" : 3.206,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.206,\n",
      "            \"upper_bound\" : 3.448,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.448,\n",
      "            \"upper_bound\" : 3.69,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 3.21, 2.27, 2.65, 2.06, 3.3, 2.96, 2.63, 2.26, 2.74, 2.77, 2.83, 2.96, 2.77, 3.38, 2.44, 3.57, 3.3, 3.17, 2.42, 3.02, 3.26, 2.81, 2.78, 2.5, 2.31, 3.19, 2.87, 3.33, 2.96, 2.12, 3.05, 3.39, 3.69, 3.12, 3.1, 3.64, 3.28, 2.84, 2.44, 2.78, 2.57, 1.29, 1.42, 1.36, 1.29, 1.51, 1.58, 1.27, 1.69, 1.82, 2.15, 2.31, 2.47, 2.06, 2.05, 2.0, 1.68, 1.33, 1.86, 1.62, 1.33, 1.3, 1.47, 1.33, 1.51, 1.55, 1.48, 1.64, 1.73, 1.96, 1.78, 1.58, 1.82, 2.11, 1.75, 1.68, 1.75, 1.56, 1.75, 1.8, 1.92, 1.83, 1.63, 1.71, 1.74, 1.56, 1.56, 1.62, 1.6 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c13\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 560.7528089887641,\n",
      "      \"sum\" : 49907.0,\n",
      "      \"std_dev\" : 145.24657693070466,\n",
      "      \"min\" : 290.0,\n",
      "      \"max\" : 937.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 290.0,\n",
      "            \"upper_bound\" : 354.7,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 354.7,\n",
      "            \"upper_bound\" : 419.4,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 419.4,\n",
      "            \"upper_bound\" : 484.1,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 484.1,\n",
      "            \"upper_bound\" : 548.8,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 548.8,\n",
      "            \"upper_bound\" : 613.5,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 613.5,\n",
      "            \"upper_bound\" : 678.2,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 678.2,\n",
      "            \"upper_bound\" : 742.9,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 742.9,\n",
      "            \"upper_bound\" : 807.6,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 807.6,\n",
      "            \"upper_bound\" : 872.3,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 872.3,\n",
      "            \"upper_bound\" : 937.0,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 625.0, 480.0, 450.0, 495.0, 290.0, 345.0, 937.0, 625.0, 428.0, 660.0, 406.0, 710.0, 562.0, 438.0, 415.0, 672.0, 315.0, 510.0, 488.0, 312.0, 680.0, 562.0, 325.0, 607.0, 434.0, 385.0, 407.0, 495.0, 345.0, 372.0, 564.0, 625.0, 465.0, 365.0, 380.0, 380.0, 378.0, 352.0, 466.0, 342.0, 580.0, 630.0, 530.0, 560.0, 600.0, 650.0, 695.0, 720.0, 515.0, 580.0, 590.0, 600.0, 780.0, 520.0, 550.0, 855.0, 830.0, 415.0, 625.0, 650.0, 550.0, 500.0, 480.0, 425.0, 675.0, 640.0, 725.0, 480.0, 880.0, 660.0, 620.0, 520.0, 680.0, 570.0, 675.0, 615.0, 520.0, 695.0, 685.0, 750.0, 630.0, 510.0, 470.0, 660.0, 740.0, 750.0, 835.0, 840.0, 560.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  Main:68 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  Main:146 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-25d26128-4b19-459e-965f-6560f191f926\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:22 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-38afc596-fc15-4c5d-b8c5-fa9981ec76a9\u001b[0m\n",
      "\n",
      "\u001b[34m2023-01-11 01:52:23,240 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2023-01-11 01:52:23,240 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7fb6cb6469d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: kevins-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='kevins-monitoring-schedule',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: kevins-monitoring-schedule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Deleting Data Quality Job Definition with name: data-quality-job-definition-2023-01-11-01-55-52-756\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: xgboost-2023-01-11-01-40-14-643\n",
      "INFO:sagemaker:Deleting endpoint with name: xgboost-2023-01-11-01-40-14-643\n"
     ]
    }
   ],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using Clarify. We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_predictor.endpoint_name,\n",
    "    instance_count=1,\n",
    "    instance_type='m1.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type='text/csv',\n",
    ")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "    explainability_config=shap_config,\n",
    "    model_config=model_config,\n",
    "    headers=train.columns.to_list()[1:],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "\n",
    "explainability_uri =f's3://{bucket}/model-explainability'\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.daily()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2023-01-11-14-07-35-661\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
